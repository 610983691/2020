#集合框架
这里不再对各数据结构进行描述。仅仅查看一些关键代码和设计思想。

####Collection接口
主要是定义size(),isEmpty(),contains()等方法，这些方法是集合框架的核心。还有java8后引入的stream()接口。
###List接口

	List<E> extends Collection<E>
主要是对基于数组和链表的数据结构定义的接口。

####基于数组
那么get(int index),set(int index,E e)，这些随机访问速度是很快的。
add(int index),remove(int index),remove(E e),由于会对内部的数组元素进行逐个后移或提前，因此会比较耗时。
对于add(E e),由于是在数组arr[size]处添加元素，所以很快。

####基于链表
由于链表是未实现RandomAccess访问接口，所以基于位置的操作会比较耗时。
而remove(E e),由于只需要拆链和建链两个操作，所以比较快。
add(E e)因为默认添加在链表尾部，所以很快。
remove(int index)，会迭代到对应位置再做删除，因此应该和基于数组的操作耗时差不多。

###Queue

	Deque extends Queue
基于双端队列接口可以实现栈、队列。

###
LinkedList实现了Deque接口的。
ArrayDeque也实现了Deque接口。看API文档，此类用作队列时会比LinkedList更快，用作栈时比Stack快。



> 那用作栈时，ArrayDeque和LinkedList相比呢？

####ArrayDeque源码

下面是关键的扩容方法，刚开始还奇怪为啥要有两次arrayCopy,还说会比LinkedList用作队列快。仔细看代码，当队首有元素出队时，其实copy的长度是当前容量。很明显是一个循环数组实现的双端队列。

	    private void doubleCapacity() {
        assert head == tail;
        int p = head;
        int n = elements.length;
        int r = n - p; // number of elements to the right of p
        int newCapacity = n << 1;
        if (newCapacity < 0)
            throw new IllegalStateException("Sorry, deque too big");
        Object[] a = new Object[newCapacity];
        System.arraycopy(elements, p, a, 0, r);
        System.arraycopy(elements, 0, a, r, p);
        elements = a;
        head = 0;
        tail = n;
    }

但这貌似还不能说明用作队列比LinkedList快呀，毕竟LinkedList不用扩容。LinkedList唯一比ArrayDeque耗时在于它会创建一个链节点。就因为这？

###HashMap

注意几个关键参数：

	DEFAULT_INITIAL_CAPACITY = 1 << 4; 
	
	TREEIFY_THRESHOLD = 8;//链节点转红黑树的阈值

	UNTREEIFY_THRESHOLD = 6; //红黑树转链节点的阈值

	MIN_TREEIFY_CAPACITY = 64; //转红黑树的前提 ，hash数组至少为64才行，否则就进行扩容，而不是转红黑树

看源码

	final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
						//这里，链表长度大于=8，会treeIfbin.别急
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }


	final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
		//这里！table.length<64,会resize扩容，不会直接转红黑树
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            do {
                TreeNode<K,V> p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }


	  final void removeTreeNode(HashMap<K,V> map, Node<K,V>[] tab,
                                  boolean movable) {
            int n;
            if (tab == null || (n = tab.length) == 0)
                return;
            int index = (n - 1) & hash;
            TreeNode<K,V> first = (TreeNode<K,V>)tab[index], root = first, rl;
            TreeNode<K,V> succ = (TreeNode<K,V>)next, pred = prev;
            if (pred == null)
                tab[index] = first = succ;
            else
                pred.next = succ;
            if (succ != null)
                succ.prev = pred;
            if (first == null)
                return;
            if (root.parent != null)
                root = root.root();
			//这里会转链表
            if (root == null || root.right == null ||
                (rl = root.left) == null || rl.left == null) {
                tab[index] = first.untreeify(map);  // too small
                return;
            }
			....
		}
 只有在root的左边为空或者右边为空的时候，才会转链表。这个时候，红黑树的节点个数应该为1,2,0.

resize的split方法才会用到UNTREEIFY_THRESHOLD，这个在扩容的时候，由于所有节点会rehash到table中，所以红黑树节点会变少。只有少于该数量的时候，才会将该节点转为链表。

###HashSet 

内部是一个hashmap，每次put的值作为内部hashmap的key。map的value是final的object.


> 为啥用final Object 而不是final boolean作为value呢？

	 final static Object obj = new Object();
    final  static Boolean b = Boolean.valueOf(false);

    public static void main(String[] args) {
       System.out.println(ObjectSizeCalculator.getObjectSize(obj));
        System.out.println(ObjectSizeCalculator.getObjectSize(b));
        Map<String ,Boolean> MAP =new HashMap<String, Boolean>();
        MAP.put("",false);
    }

输出都是16字节，因此使用object，没有使用boolean。并没有像我想的那样Boolean会省空间。

###BitSet

一个位图，常见的用于对数据的去重，排序。类似redis的bitmap的作用
例如：一个电话号码是否存在等。但它排重所占用的内存随着数据量的增大而线性增大，并且对于一些64bit的大数是无法通过这个方式来实现。

自己的样例代码,先生成一个文件。当然这个文件并不大，共1KW个uint数。
	
	 public static void main(String[] args) throws IOException {
        Random r = new Random();
        Path c = Paths.get("E:\\devtools\\tongjie\\temp\\numbers.txt");
        for (int i = 0; i < 10000000; i++) {//先生成文件
            int rand = r.nextInt();
            if (rand < 0) {
                rand = -rand;
            }
            Files.write(c, (rand + System.lineSeparator()).getBytes(), StandardOpenOption.APPEND);
        }

    }

查看磁盘io，笔记本是有点太慢了。就不优化代码了，，，直接缓冲区会不会更快、?
	
	

然后基于该文件的查找

基于此可以实现一个布隆过滤器。布隆过滤的核心逻辑就是用N个互不相关的hash函数来计算key在bitset中的位置并且置为1，对不存在的值判断准确。对存在的值判断存在误判的情况。
设计一个好的布隆过滤器的关键在于hash函数个数，map长度，要判断的元素个数，误判率来综合确定。


> *参考文章：
[https://blog.nekolr.com/2019/08/30/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/](https://blog.nekolr.com/2019/08/30/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/ "布隆过滤器")

用一个表来存储可能误判的元素？？？怎么做到呢？

###guava的布隆过滤器
想到公司目前正在做的流量分析引擎，在网络关系复杂的时候，可以采用布隆过滤器来对大量的数据去重。但截至现在的数据量貌似还用不到。待数据量进一步加大到内存无法用hash过滤的时候，可以考虑使用布隆过滤器。




> BloomFilter源码解读
> 参考：[https://zhuanlan.zhihu.com/p/85042394](https://zhuanlan.zhihu.com/p/85042394)

1.k个hash函数的hash码生成，如果是string/int等java的普通类型还好，如果判断的数据是java对象，那么如何计算这个对象的k个hash码呢？
2.误判率和元素个数插入，用这两个值bloomfilter内部会自己计算bit个数。

bloomfilter使用自定义的Funnel<?>类，来告诉bloomfilter应该如何计算hash码。
	
	//只有一个方法
	public interface Funnel<T> extends Serializable {
	    void funnel(T var1, PrimitiveSink var2);
	}

	public interface PrimitiveSink {
	    PrimitiveSink putByte(byte var1);
	
	    PrimitiveSink putBytes(byte[] var1);
		...
		...
	}

>PrimitiveSink接收T var1 ,提供一些putbyte,putstring等基础类型的方法来计算hash码。

	
	public final class BloomFilter<T> implements Predicate<T>, Serializable {
	    private final LockFreeBitArray bits;//bit位数组，用于标记
	    private final int numHashFunctions;//hash函数个数
	    private final Funnel<? super T> funnel; //传入的Funnel类型
	    private final BloomFilter.Strategy strategy; //这个内部接口，定义了put,maycontas方法。
	}

查看bloomfilter的create方法。Default fPP 0.03, 即3%。

	@VisibleForTesting
    static <T> BloomFilter<T> create(Funnel<? super T> funnel, long expectedInsertions, double fpp, BloomFilter.Strategy strategy) {
		//先是参数校验
        Preconditions.checkNotNull(funnel);
        Preconditions.checkArgument(expectedInsertions >= 0L, "Expected insertions (%s) must be >= 0", expectedInsertions);
        Preconditions.checkArgument(fpp > 0.0D, "False positive probability (%s) must be > 0.0", fpp);
        Preconditions.checkArgument(fpp < 1.0D, "False positive probability (%s) must be < 1.0", fpp);
        Preconditions.checkNotNull(strategy);
        if (expectedInsertions == 0L) {
            expectedInsertions = 1L;
        }
		//根据插入数量和错误率来计算bit长度
        long numBits = optimalNumOfBits(expectedInsertions, fpp);
        int numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits);//获取hash函数个数

        try {
            return new BloomFilter(new LockFreeBitArray(numBits), numHashFunctions, funnel, strategy);//返回实例 
        } catch (IllegalArgumentException var10) {
            throw new IllegalArgumentException("Could not create BloomFilter of " + numBits + " bits", var10);
        }
    }

	
位数组，由于bitset只有int位，显然不够，因此bloomfilter实现了自己的bitarray.

	static final class LockFreeBitArray {
        private static final int LONG_ADDRESSABLE_BITS = 6;
        final AtomicLongArray data;
        private final LongAddable bitCount;

        LockFreeBitArray(long bits) {
            Preconditions.checkArgument(bits > 0L, "data length is zero!");
            this.data = new AtomicLongArray(Ints.checkedCast(LongMath.divide(bits, 64L, RoundingMode.CEILING)));
            this.bitCount = LongAddables.create();
        }

        LockFreeBitArray(long[] data) {
            Preconditions.checkArgument(data.length > 0, "data length is zero!");
            this.data = new AtomicLongArray(data);
            this.bitCount = LongAddables.create();
            long bitCount = 0L;
            long[] var4 = data;
            int var5 = data.length;

            for(int var6 = 0; var6 < var5; ++var6) {
                long value = var4[var6];
                bitCount += (long)Long.bitCount(value);
            }

            this.bitCount.add(bitCount);
        }
	}

	boolean set(long bitIndex) {
            if (this.get(bitIndex)) {
                return false;
            } else {
                int longIndex = (int)(bitIndex >>> 6);
                long mask = 1L << (int)bitIndex;

                long oldValue;
                long newValue;
                do {
                    oldValue = this.data.get(longIndex);
                    newValue = oldValue | mask;
                    if (oldValue == newValue) {
                        return false;
                    }
                } while(!this.data.compareAndSet(longIndex, oldValue, newValue));

                this.bitCount.increment();
                return true;
            }
        }

		//这里计算索引的时候，把long转int，意味着最多只能2*32，*2^6=。大约64*21亿个位？最多128亿个元素
        boolean get(long bitIndex) {
            return (this.data.get((int)(bitIndex >>> 6)) & 1L << (int)bitIndex) != 0L;
        }




	